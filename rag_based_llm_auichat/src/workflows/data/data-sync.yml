name: AUIChat Deployment and Data Sync
on:
  push:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * *'  # Run data sync at 2 AM UTC daily

jobs:
  sync-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      
      - name: Install dependencies
        run: pip install -r requirements.txt
      
      - name: Run data sync script
        run: python sync_qdrant.py

  deploy-vertex:
    runs-on: ubuntu-latest
    needs: sync-data
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install gcsfs google-cloud-storage google-cloud-aiplatform zenml
          
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
          
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v1
        
      - name: Configure ZenML
        run: |
          # Set up ZenML GCP stack
          zenml artifact-store register gcp-artifact-store --flavor=gcp --path=gs://auichat-models-${{ secrets.GCP_PROJECT_ID }} || true
          zenml orchestrator register local-orchestrator --flavor=local || true
          zenml experiment-tracker register mlflow-tracker --flavor=mlflow || true
          zenml stack register gcp-stack -a gcp-artifact-store -o local-orchestrator -e mlflow-tracker || true
          zenml stack set gcp-stack
          
      - name: Deploy model to Vertex AI
        env:
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          REGION: ${{ secrets.GCP_REGION }}
        run: |
          # Create Google Cloud Storage bucket if it doesn't exist
          gsutil ls -b gs://auichat-models-$PROJECT_ID || gsutil mb -l $REGION gs://auichat-models-$PROJECT_ID
          
          # Run the deployment pipeline
          cd rag_based_llm_auichat
          python src/main.py vertex
          
      - name: Report deployment status
        if: always()
        run: |
          if [ $? -eq 0 ]; then
            echo "✅ Model deployed successfully to Vertex AI"
          else
            echo "❌ Model deployment failed"
          fi
